{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4445fe48-359b-4894-a7b4-d617e2423f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "import sympy as sympy\n",
    "import mendeleev as ptable\n",
    "import random as random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a825f019-4f40-42d3-9622-93a4729fff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class molecular_graph:\n",
    "    def __init__(self, orbital_overlaps, n_atoms, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        self.n_atoms = n_atoms\n",
    "        self.orbital_overlaps = orbital_overlaps\n",
    "        self.maximum_s_el = maximum_s_el\n",
    "        self.maximum_p_el = maximum_p_el\n",
    "        self.maximum_d_el = maximum_d_el\n",
    "        self.maximum_f_el = maximum_f_el\n",
    "\n",
    "    def build_adj_matrix(self, n_atoms, orbital_overlaps):\n",
    "        self.labeled_atom_list = np.arange(0, n_atoms)\n",
    "        self.adj_matrix = np.array([])\n",
    "        self.adj_matrix = self.adj_matrix[np.newaxis, :]\n",
    "        #classifying all atoms in complex as either engaging in orbital overlap (bonding M.O) or not (nonbonding state), starting from atom 1 to the nth atom in the system:\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for i in np.arange(0, n_atoms):\n",
    "            ith_adjacency_row = np.zeros(n_atoms)\n",
    "            ith_adjacecy_row = list(ith_adjacency_row)\n",
    "            for j in np.arange(0, len(orbital_overlaps)):\n",
    "                if str(i+1) in orbital_overlaps[j]:\n",
    "                    if orbital_overlaps[j][0] == str(i+1):\n",
    "                        overlapped_adjacent = int(orbital_overlaps[j][2])\n",
    "                        ith_adjacency_row[overlapped_adjacent - 1] = 1\n",
    "                j += 1\n",
    "            self.adj_matrix = np.append(self.adj_matrix, ith_adjacency_row)\n",
    "            i += 1\n",
    "        self.adj_matrix = np.reshape(self.adj_matrix, (n_atoms, n_atoms))\n",
    "        return self.adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a86019a-f350-4fbb-a1e7-8f09f7c52480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.244\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0\n",
      "        value: 3.75\n",
      "        value: 8\n",
      "        value: 0.097\n",
      "        value: 0.055\n",
      "        value: 498\n",
      "        value: 4.62\n",
      "        value: 2.91\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 3.15\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.5\n",
      "        value: 2.99\n",
      "        value: 57\n",
      "        value: 0.068\n",
      "        value: -0.19\n",
      "        value: 1.18\n",
      "        value: 10.98\n",
      "        value: 2.8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.88\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 3.1\n",
      "        value: 3.5\n",
      "        value: 8\n",
      "        value: 590\n",
      "        value: 0.00024\n",
      "        value: 0.0543\n",
      "        value: 3.88\n",
      "        value: 2.98\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.7\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 5.4\n",
      "        value: 5\n",
      "        value: 8\n",
      "        value: 0.0071\n",
      "        value: 4.1\n",
      "        value: 0.00044\n",
      "        value: 2.85\n",
      "        value: 3.25\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.98\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.9\n",
      "        value: 3\n",
      "        value: 57\n",
      "        value: -0.0048\n",
      "        value: 0.022\n",
      "        value: -0.095\n",
      "        value: 2.56\n",
      "        value: 9.58\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.97\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.7\n",
      "        value: 3.38\n",
      "        value: 57\n",
      "        value: -0.00011\n",
      "        value: 0.0091\n",
      "        value: 0.228\n",
      "        value: 3.19\n",
      "        value: 7.43\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.66\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 4.7\n",
      "        value: 5.2\n",
      "        value: 8\n",
      "        value: 45\n",
      "        value: -0.088\n",
      "        value: 0.00512\n",
      "        value: 4.73\n",
      "        value: 2.9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "/Users/haydenprescott/DLNNP/DL_GCN_Potential/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "def convert_data_to_records():\n",
    "    test_csv = \"/users/haydenprescott/documents/test.csv\"\n",
    "    record_filepath = test_path = os.path.join(os.getcwd(), \"test.tfrecords\")\n",
    "    test_dataset = pd.read_csv(test_csv).values\n",
    "    with tf.compat.v1.python_io.TFRecordWriter(record_filepath) as writer:\n",
    "        for row in test_dataset:\n",
    "            features, label = row[:-1], row[-1]\n",
    "            example_data_piece = tf.train.Example()\n",
    "            example_data_piece.features.feature[\"features\"].float_list.value.extend(features)\n",
    "            example_data_piece.features.feature[\"label\"].float_list.value.append(label)\n",
    "            writer.write(example_data_piece.SerializeToString())\n",
    "            print(example_data_piece)\n",
    "    return record_filepath\n",
    "\n",
    "\n",
    "record_types = convert_data_to_records()\n",
    "print(record_types)\n",
    "#contents = contents.read()\n",
    "#print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4806057b-06e2-4551-a716-7084bded0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': [0.0, 2.5, 3.1, 5.4, 1.9, 2.7, 4.7], 'ACSF': [3.75, 2.99, 3.5, 5.0, 3.0, 3.38, 5.2], 'z': [8.0, 57.0, 8.0, 8.0, 57.0, 57.0, 8.0], 'd1': [0.097, 0.068, 590.0, 0.0071, -0.0048, -0.00011, 45.0], 'd2': [0.055, -0.19, 0.00024, 4.1, 0.022, 0.0091, -0.088], 'd3': [498.0, 1.18, 0.0543, 0.00044, -0.095, 0.228, 0.00512], 'exp1': [4.62, 10.98, 3.88, 2.85, 2.56, 3.19, 4.73], 'exp2': [2.91, 2.8, 2.98, 3.25, 9.58, 7.43, 2.9], 'exp3': [0.244, 3.15, 0.88, 0.7, 2.98, 0.97, 0.66]}\n"
     ]
    }
   ],
   "source": [
    "def initialize_dataset(csv_filepath):\n",
    "    records_dict = {}\n",
    "    r_set = np.array([])\n",
    "    ACSF_set = np.array([])\n",
    "    z_set = np.array([])\n",
    "    d1_set = np.array([])\n",
    "    d2_set = np.array([])\n",
    "    d3_set = np.array([])\n",
    "    exp1_set = np.array([])\n",
    "    exp2_set = np.array([])\n",
    "    exp3_set = np.array([])\n",
    "    molecular_datafile = open(csv_filepath, \"r\")\n",
    "    features = pd.read_csv(csv_filepath)\n",
    "    columns = features.columns\n",
    "    placeholder_column = columns[0]\n",
    "    del placeholder_column\n",
    "    r_vals = features[\"r\"]\n",
    "    ACSF_vals = features[\"ACSF\"]\n",
    "    z_vals = features[\"z\"]\n",
    "    d1_vals = features[\"d1\"]\n",
    "    d2_vals = features[\"d2\"]\n",
    "    d3_vals = features[\"d3\"]\n",
    "    exp1_vals = features[\"exp1\"]\n",
    "    exp2_vals = features[\"exp2\"]\n",
    "    exp3_vals = features[\"exp3\"]\n",
    "    for i in r_vals:\n",
    "        r_set = np.append(r_set, i)\n",
    "    for j in ACSF_vals:\n",
    "        ACSF_set = np.append(ACSF_set, j)\n",
    "    for k in z_vals:\n",
    "        z_set = np.append(z_set, k) \n",
    "    for l in d1_vals:\n",
    "        d1_set = np.append(d1_set, l)\n",
    "    for m in d2_vals:\n",
    "        d2_set = np.append(d2_set, m)\n",
    "    for n in d3_vals:\n",
    "        d3_set = np.append(d3_set, n)\n",
    "    for o in exp1_vals:\n",
    "        exp1_set = np.append(exp1_set, o)\n",
    "    for p in exp2_vals:\n",
    "        exp2_set = np.append(exp2_set, p)\n",
    "    for q in exp3_vals:\n",
    "        exp3_set = np.append(exp3_set, q)\n",
    "    record_keys = [\"r\", \"ACSF\", \"z\", \"d1\", \"d2\", \"d3\", \"exp1\", \"exp2\", \"exp3\"]\n",
    "    num_records = np.arange(0, len(record_keys))\n",
    "    for i in num_records:\n",
    "        if record_keys[i] == \"r\":\n",
    "            records_dict.update({record_keys[i]:list(r_set)})\n",
    "        elif record_keys[i] == \"ACSF\":\n",
    "            records_dict.update({record_keys[i]:list(ACSF_set)})\n",
    "        elif record_keys[i] == \"z\":\n",
    "            records_dict.update({record_keys[i]:list(z_set)})\n",
    "        elif record_keys[i] == \"d1\":\n",
    "            records_dict.update({record_keys[i]:list(d1_set)})\n",
    "        elif record_keys[i] == \"d2\":\n",
    "            records_dict.update({record_keys[i]:list(d2_set)})\n",
    "        elif record_keys[i] == \"d3\":\n",
    "            records_dict.update({record_keys[i]:list(d3_set)})\n",
    "        elif record_keys[i] == \"exp1\":\n",
    "            records_dict.update({record_keys[i]:list(exp1_set)})\n",
    "        elif record_keys[i] == \"exp2\":\n",
    "            records_dict.update({record_keys[i]:list(exp2_set)})\n",
    "        elif record_keys[i] == \"exp3\":\n",
    "            records_dict.update({record_keys[i]:list(exp3_set)})\n",
    "        i += 1        \n",
    "    return records_dict\n",
    "\n",
    "def take_data_batch(csv_filepath):\n",
    "    data_dict = initialize_dataset(csv_filepath)\n",
    "    example_set = tf.train.Example(features = tf.train.Features(feature={\n",
    "    'r': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data_dict[\"r\"][0]])),\n",
    "    'ACSF': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data_dict[\"ACSF\"][0]])),\n",
    "    'z': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data_dict['z'][0]])),\n",
    "    'd1': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data_dict['d1'][0]])),\n",
    "    'd2': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data_dict['d2'][0]])),\n",
    "    'd3': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data_dict['d3'][0]])),\n",
    "    'exp1': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data_dict['exp1'][0]])),\n",
    "    'exp2': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data_dict['exp2'][0]])),\n",
    "    'exp3': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data_dict['exp3'][0]]))\n",
    "    }))\n",
    "    return example_set\n",
    "csv_filepath = csv_filepath = \"/users/haydenprescott/documents/test.csv\"\n",
    "print(initialize_dataset(csv_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb2b54c7-c81b-400f-beec-4f9779321497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_TF_records_file(csv_filepath):\n",
    "    encoded_dataset = take_data_batch(csv_filepath)\n",
    "    with tf.io.TFRecordWriter(\"test_data.tfrecord\") as writer:\n",
    "        writer.write(encoded_dataset.SerializeToString())\n",
    "\n",
    "csv_filepath = \"/users/haydenprescott/documents/test.csv\"\n",
    "write_TF_records_file(csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0db13fbe-ae91-4f27-9d4b-22561f61c06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'r' b'ACSF' b'z' b'd1' b'd2' b'd3' b'exp1' b'exp2' b'exp3']\n",
      " [b'0.0' b'3.75' b'8.0' b'0.097' b'0.055' b'498.0' b'4.62' b'2.91'\n",
      "  b'0.244']\n",
      " [b'2.5' b'2.99' b'57.0' b'0.068' b'-0.19' b'1.18' b'10.98' b'2.8'\n",
      "  b'3.15']\n",
      " [b'3.1' b'3.5' b'8.0' b'590.0' b'0.00024' b'0.0543' b'3.88' b'2.98'\n",
      "  b'0.88']\n",
      " [b'5.4' b'5.0' b'8.0' b'0.0071' b'4.1' b'0.00044' b'2.85' b'3.25' b'0.7']\n",
      " [b'1.9' b'3.0' b'57.0' b'-0.0048' b'0.022' b'-0.095' b'2.56' b'9.58'\n",
      "  b'2.98']\n",
      " [b'2.7' b'3.38' b'57.0' b'-0.00011' b'0.0091' b'0.228' b'3.19' b'7.43'\n",
      "  b'0.97']\n",
      " [b'4.7' b'5.2' b'8.0' b'45.0' b'-0.088' b'0.00512' b'4.73' b'2.9'\n",
      "  b'0.66']], shape=(8, 9), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "def nodeset_position_fxn(nodeset_proto):\n",
    "    feature_descriptor = {\"z\" : tf.io.FixedLenFeature([], tf.float32), \"r\" : tf.io.FixedLenFeature([], tf.float32), \"ACSF\" : tf.io.FixedLenFeature([], tf.float32), \"d1\" : tf.io.FixedLenFeature([], tf.float32), \"d2\" : tf.io.FixedLenFeature([], tf.float32), \"d3\" : tf.io.FixedLenFeature([], tf.float32), \"exp1\" : tf.io.FixedLenFeature([], tf.float32), \"exp2\" : tf.io.FixedLenFeature([], tf.float32), \"exp3\" : tf.io.FixedLenFeature([], tf.float32)}\n",
    "    position_fxn = tf.io.parse_single_example(nodeset_proto, feature_descriptor)\n",
    "    return position_fxn\n",
    "\n",
    "csv_filepath = \"/users/haydenprescott/documents/test.csv\"\n",
    "def record_floats(value):\n",
    "    r_floats = tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n",
    "    return r_floats\n",
    "\n",
    "def serialize_floats(r_val, ACSF_val, z_val, d1_val, d2_val, d3_val, exp1_val, exp2_val, exp3_val, csv_filepath):\n",
    "    initial_state_feature = {\"r\":record_floats(r_val), \"ACSF\":record_floats(ACSF_val), \"z\":record_floats(z_val), \"d1\":record_floats(d1_val), \"d2\":record_floats(d2_val), \"d3\":record_floats(d3_val), \"exp1\":record_floats(exp1_val), \"exp2\":record_floats(exp2_val), \"exp3\":record_floats(exp3_val)}\n",
    "    initial_state_proto = tf.train.Example(features = tf.train.Features(feature = initial_state_feature))\n",
    "    initial_state_records = initial_state_proto.SerializeToString()\n",
    "    return initial_state_records\n",
    "\n",
    "def convert_floats_to_records(csv_filepath, record_filepath, record_filename):\n",
    "    data_dict = initialize_dataset(csv_filepath)\n",
    "    previous_record_path = Path(record_filename)\n",
    "    serialized_input_floats = []\n",
    "    n_input_vals = np.arange(0, (len(data_dict['r'])))\n",
    "    i = 0\n",
    "    for i in n_input_vals:\n",
    "        r, ACSF, z, d1, d2, d3, exp1, exp2, exp3 = data_dict['r'][i], data_dict['ACSF'][i], data_dict['z'][i], data_dict['d1'][i], data_dict['d2'][i], data_dict['d3'][i], data_dict['exp1'][i], data_dict['exp2'][i], data_dict['exp3'][i]\n",
    "        all_floats_per_molecule = (r, ACSF, z, d1, d2, d3, exp1, exp2, exp3)\n",
    "        serialized_input_floats.append(all_floats_per_molecule)\n",
    "        initial_state_data = tf.constant([['r', 'ACSF', 'z', 'd1', 'd2', 'd3','exp1', 'exp2', 'exp3']])\n",
    "    with tf.io.TFRecordWriter(record_filepath) as record_writer:\n",
    "        for r, ACSF, z, d1, d2, d3, exp1, exp2, exp3 in serialized_input_floats:\n",
    "            serialized_input_floats = serialize_floats(r, ACSF, z, d1, d2, d3, exp1, exp2, exp3, csv_filepath)\n",
    "            record_writer.write(serialized_input_floats)\n",
    "            record_batch = tf.data.TFRecordDataset(record_filename)\n",
    "            record_batch = record_batch.map(nodeset_position_fxn)\n",
    "            ith_atom_features = tf.constant([[str(r), str(ACSF), str(z), str(d1), str(d2), str(d3), str(exp1), str(exp2), str(exp3)]])\n",
    "            initial_state_data = tf.concat([initial_state_data, ith_atom_features], 0)\n",
    "    return initial_state_data\n",
    "            \n",
    "csv_filepath = \"/users/haydenprescott/documents/test.csv\"\n",
    "record_filename = \"test_data.tfrecord\" \n",
    "record_filepath = \"/users/haydenprescott/test_data.tfrecord\"\n",
    "print(convert_floats_to_records(csv_filepath, record_filepath, record_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "808ff429-4b9d-434d-b7b1-557a7e3e1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[b'r', b'ACSF', b'z', b'd1', b'd2', b'd3', b'exp1', b'exp2',\n",
      "        b'exp3'],\n",
      "       [b'0.0', b'3.75', b'8.0', b'0.097', b'0.055', b'498.0', b'4.62',\n",
      "        b'2.91', b'0.244'],\n",
      "       [b'2.5', b'2.99', b'57.0', b'0.068', b'-0.19', b'1.18', b'10.98',\n",
      "        b'2.8', b'3.15'],\n",
      "       [b'3.1', b'3.5', b'8.0', b'590.0', b'0.00024', b'0.0543', b'3.88',\n",
      "        b'2.98', b'0.88'],\n",
      "       [b'5.4', b'5.0', b'8.0', b'0.0071', b'4.1', b'0.00044', b'2.85',\n",
      "        b'3.25', b'0.7'],\n",
      "       [b'1.9', b'3.0', b'57.0', b'-0.0048', b'0.022', b'-0.095',\n",
      "        b'2.56', b'9.58', b'2.98'],\n",
      "       [b'2.7', b'3.38', b'57.0', b'-0.00011', b'0.0091', b'0.228',\n",
      "        b'3.19', b'7.43', b'0.97'],\n",
      "       [b'4.7', b'5.2', b'8.0', b'45.0', b'-0.088', b'0.00512', b'4.73',\n",
      "        b'2.9', b'0.66']], dtype=object), array([[b'0.0', b'3.75', b'8.0', b'0.097', b'0.055', b'498.0', b'4.62',\n",
      "        b'2.91', b'0.244'],\n",
      "       [b'2.5', b'2.99', b'57.0', b'0.068', b'-0.19', b'1.18', b'10.98',\n",
      "        b'2.8', b'3.15'],\n",
      "       [b'3.1', b'3.5', b'8.0', b'590.0', b'0.00024', b'0.0543', b'3.88',\n",
      "        b'2.98', b'0.88'],\n",
      "       [b'5.4', b'5.0', b'8.0', b'0.0071', b'4.1', b'0.00044', b'2.85',\n",
      "        b'3.25', b'0.7'],\n",
      "       [b'1.9', b'3.0', b'57.0', b'-0.0048', b'0.022', b'-0.095',\n",
      "        b'2.56', b'9.58', b'2.98'],\n",
      "       [b'2.7', b'3.38', b'57.0', b'-0.00011', b'0.0091', b'0.228',\n",
      "        b'3.19', b'7.43', b'0.97'],\n",
      "       [b'4.7', b'5.2', b'8.0', b'45.0', b'-0.088', b'0.00512', b'4.73',\n",
      "        b'2.9', b'0.66']], dtype=object))\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def build_graph_tensor(csv_filepath, record_filepath, record_filename):\n",
    "    initial_graph_tensor = convert_floats_to_records(csv_filepath, record_filepath, record_filename)\n",
    "    input_graph_tensor = tf.transpose(initial_graph_tensor)\n",
    "    input_rvals = input_graph_tensor[0][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_ACSFvals = input_graph_tensor[1][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_zvals = input_graph_tensor[2][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_d1vals = input_graph_tensor[3][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_d2vals = input_graph_tensor[4][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_d3vals = input_graph_tensor[5][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_exp1vals = input_graph_tensor[6][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_exp2vals = input_graph_tensor[7][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_exp3vals = input_graph_tensor[8][1:len(input_graph_tensor) - 1].numpy()\n",
    "    input_graph_tensor = np.array([input_rvals, input_ACSFvals, input_zvals, input_d1vals, input_d2vals, input_d3vals, input_exp1vals, input_exp2vals, input_exp3vals])\n",
    "    input_graph_tensor = input_graph_tensor.transpose()\n",
    "    initial_graph_tensor = initial_graph_tensor.numpy()\n",
    "    initial_state_and_GNN_input = (initial_graph_tensor, input_graph_tensor)\n",
    "    return initial_state_and_GNN_input\n",
    "\n",
    "graph_tensor = build_graph_tensor(csv_filepath, record_filepath, record_filename)\n",
    "print(build_graph_tensor(csv_filepath, record_filepath, record_filename))\n",
    "print(type(build_graph_tensor(csv_filepath, record_filepath, record_filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e226b6a2-9fe1-448d-be6b-63bf901226e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class find_orbitals_get_characteristics:\n",
    "    def __init__(self, molecular_formula, seed_structure_directory, element, graph_tensor):\n",
    "        self.molecular_formula = molecular_formula\n",
    "        self.seed_structure_directory = seed_structure_directory\n",
    "        self.element = element\n",
    "        self.graph_tensor = graph_tensor\n",
    "\n",
    "    def find_atomic_symbol(self, element):\n",
    "        characteristic_list = []\n",
    "        blanks = np.array([])\n",
    "        for i in np.arange(0, len(str(element))):\n",
    "            characteristic_list.append(str(element)[i])\n",
    "        for j in np.arange(0, len(characteristic_list)):\n",
    "            if characteristic_list[j] == \" \":\n",
    "                blanks = np.append(blanks, j)\n",
    "        atomic_symbol = str(element)[int(blanks[0]) + 1:int(blanks[1])]\n",
    "        return atomic_symbol\n",
    "\n",
    "    def find_atomic_number(self, element):\n",
    "        characteristic_list = []\n",
    "        blanks = np.array([])\n",
    "        for i in np.arange(0, len(str(element))):\n",
    "            characteristic_list.append(str(element)[i])\n",
    "        for j in np.arange(0, len(characteristic_list)):\n",
    "            if characteristic_list[j] == \" \":\n",
    "                blanks = np.append(blanks, j)\n",
    "        atomic_symbol = str(element)[0:int(blanks[0])]\n",
    "        return atomic_symbol\n",
    "\n",
    "    \n",
    "    def get_symbols_and_numbers(self, molecular_formula, seed_structure_directory, graph_tensor):\n",
    "        seed_structure = seed_structure_directory + \"/\" + str(molecular_formula) + \".csv\"\n",
    "        molecular_details = open(seed_structure, \"r\")\n",
    "        molecular_details = pd.read_csv(seed_structure)\n",
    "        element_symbols = np.array(molecular_details['symbol'][0:len(graph_tensor[0]) - 1])\n",
    "        atomic_numbers = np.array([])\n",
    "        valence_blocks = np.array([])\n",
    "        element_set = ptable.get_all_elements()\n",
    "        for j in np.arange(0, len(element_symbols)):\n",
    "            for i in np.arange(0, len(element_set)):\n",
    "                if str.encode(self.find_atomic_symbol(element_set[i])) == str.encode(element_symbols[j]):\n",
    "                    atomic_numbers = np.append(atomic_numbers, int(self.find_atomic_number(element_set[i])))\n",
    "                    valence_blocks = np.append(valence_blocks, element_set[i].block)\n",
    "        return element_symbols, atomic_numbers, valence_blocks\n",
    "\n",
    "    \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03645e09-f53a-434f-b71a-0a309251a579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3916162a-bdb1-41d5-8888-66b0178f2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['La', 'O', 'O', 'La', 'O', 'O', 'La'], dtype=object), array([57.,  8.,  8., 57.,  8.,  8., 57.]), array(['d', 'p', 'p', 'd', 'p', 'p', 'd'], dtype='<U32'))\n",
      "La\n"
     ]
    }
   ],
   "source": [
    "element = None\n",
    "molecular_characteristics = find_orbitals_get_characteristics(molecular_formula = \"La3O4\", seed_structure_directory = \"/users/haydenprescott/documents\", element = element, graph_tensor = graph_tensor)\n",
    "print(molecular_characteristics.get_symbols_and_numbers(molecular_characteristics.molecular_formula, molecular_characteristics.seed_structure_directory, molecular_characteristics.graph_tensor))\n",
    "atomic_symbols = molecular_characteristics.find_atomic_symbol(element = ptable.get_all_elements()[56])\n",
    "print(atomic_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c186d92-ec65-4c42-baf8-b8b8bb7dd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "atomic_numbers = np.array([])\n",
    "valence_blocks = np.array([])\n",
    "element_set = ptable.get_all_elements()\n",
    "for j in np.arange(0, len(element_symbols)):\n",
    "    for i in np.arange(0, len(element_set)):\n",
    "        if str.encode(self.find_atomic_symbol(element_set[i])) == str.encode(element_symbols[j]):\n",
    "            atomic_numbers = np.append(atomic_numbers, int(self.find_atomic_number(element_set[i])))\n",
    "            valence_blocks = np.append(valence_blocks, element_set[i].block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2608a39-0466-4b99-a31c-dd36b5f5d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute overlaps between atomic orbitals in basis and approximate energy eigenvalues for all free-atom (with correct valency) and bonded (molecular orbital) states using extended Huckel. Compute energy changes between pure and bonded states, and construct Kohn-Sham MO's as LCAO's of basis AO's with positive (constuctive) overlaps and reduced energies:\n",
    "\n",
    "class EH_molecular_orbitals:\n",
    "    def __init__(self, input_tensor, atomic_orbital_states, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.atomic_orbital_states = atomic_orbital_states\n",
    "        self.n_atoms = n_atoms\n",
    "        self.exponential_range = exponential_range\n",
    "        self.maximum_s_el = maximum_s_el\n",
    "        self.maximum_p_el = maximum_p_el\n",
    "        self.maximum_d_el = maximum_d_el\n",
    "        self.maximum_f_el = maximum_f_el\n",
    "\n",
    "    def construct_basis_AOs(self, input_tensor, atomic_orbital_states, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        s_AO_set = sympy.Array([])\n",
    "        p_AO_set = sympy.Array([])\n",
    "        d_AO_set = sympy.Array([])\n",
    "        f_AO_set = sympy.Array([])\n",
    "        s_ref_set = sympy.Array([])\n",
    "        p_ref_set = sympy.Array([])\n",
    "        d_ref_set = sympy.Array([])\n",
    "        f_ref_set = sympy.Array([])\n",
    "        s_exp_set = sympy.Array([])\n",
    "        p_exp_set = sympy.Array([])\n",
    "        d_exp_set = sympy.Array([])\n",
    "        f_exp_set = sympy.Array([])\n",
    "        exp_set = sympy.Array([])\n",
    "        one_electron_wavefunctions = np.array([])\n",
    "        gaussian_terms = []\n",
    "        coefficient_sequence = []\n",
    "        exp_set = []\n",
    "        r = sympy.symbols(\"r\", real = True)\n",
    "        j = sympy.symbols(\"j\", real = True)\n",
    "        s_exponentials = 1\n",
    "        p_exponentials = atomic_orbital_states[\"p\"][1] - atomic_orbital_states[\"s\"]\n",
    "        d_exponentials = atomic_orbital_states[\"d\"][1] - atomic_orbital_states[\"p\"][1]\n",
    "        f_exponentials = atomic_orbital_states[\"f\"][0]\n",
    "        i = 0\n",
    "        for i in range(0, n_atoms):\n",
    "            if len(input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]]) > s_exponentials - 1:\n",
    "                exp_start = exponential_range[s_exponentials - 1]\n",
    "                s_coefficient_range = np.array([input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]].transpose()[i][0]])\n",
    "                print(s_coefficient_range)\n",
    "                j = 0\n",
    "                for j in range(0, len(s_coefficient_range)):\n",
    "                    current_basis_coeff = s_coefficient_range[j]\n",
    "                    if current_basis_coeff != 0:\n",
    "                        current_s_AO = current_basis_coeff * sympy.exp(-input_tensor[i][exp_start] * r)\n",
    "                        s_AO_set = np.append(s_AO_set, np.array([current_s_AO, i + 1]))\n",
    "                        s_ref_set = np.append(s_ref_set, current_s_AO)\n",
    "                        s_exp_set = np.append(s_exp_set, sympy.exp(-input_tensor[i][exp_start] * r))\n",
    "                        gaussian_terms.append(current_s_AO)\n",
    "                        coefficient_sequence.append(current_basis_coeff)\n",
    "                        j += s_exponentials\n",
    "            else:\n",
    "                pass\n",
    "            exp_range_vals = np.arange(exponential_range[0], exponential_range[1] + 1)\n",
    "            if len(input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]]) > s_exponentials * maximum_s_el: \n",
    "                p_coefficient_range = input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]].transpose()[i][maximum_s_el * s_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials]\n",
    "                print(p_coefficient_range)\n",
    "                j = 0\n",
    "                p_AO_contributions = 0\n",
    "                while j <= len(p_coefficient_range):\n",
    "                    current_basis_coeffs = p_coefficient_range[j: j + p_exponentials] \n",
    "                    k = 0\n",
    "                    print(current_basis_coeffs)\n",
    "                    for k in range(0, len(current_basis_coeffs)):\n",
    "                        if current_basis_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_basis_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_basis_coeffs[k]])\n",
    "                            p_exp_set = np.append(p_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r))\n",
    "                            p_AO_contributions = p_AO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += p_exponentials\n",
    "                    if j <= len(p_coefficient_range):\n",
    "                        p_AO_set = np.append(p_AO_set, np.array([p_AO_contributions, i + 1]))  \n",
    "                        p_ref_set = np.append(p_ref_set, p_AO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]]) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el:\n",
    "                d_coefficient_range = input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]].transpose()[i][maximum_s_el * s_exponentials + maximum_p_el * p_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el + d_exponentials]\n",
    "                j = 0\n",
    "                d_AO_contributions = 0\n",
    "                while j <= len(d_coefficient_range):\n",
    "                    current_basis_coeffs = d_coefficient_range[j: j + d_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_basis_coeffs)):\n",
    "                        if current_basis_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_basis_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_basis_coeffs[k]])\n",
    "                            d_exp_set = np.append(d_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r))\n",
    "                            d_AO_contributions = d_AO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += d_exponentials\n",
    "                    if j <= len(d_coefficient_range):\n",
    "                        d_AO_set = np.append(d_AO_set, np.array([d_AO_contributions, i + 1])) \n",
    "                        d_ref_set = np.append(d_ref_set, d_AO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]]) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el:\n",
    "                f_coefficient_range = input_tensor.transpose()[basis_coefficient_range[0]:basis_coefficient_range[1]].transpose()[i][s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el * d_exponentials + maximum_f_el * f_exponentials]\n",
    "                j = 0\n",
    "                f_AO_contributions = 0\n",
    "                while j <= len(f_coefficient_range):\n",
    "                    current_basis_coeffs = d_coefficient_range[j: j + f_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_basis_coeffs)):\n",
    "                        if current_basis_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_basis_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_basis_coeffs[k]])\n",
    "                            f_exp_set = np.append(f_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r))\n",
    "                            f_AO_contributions = f_AO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += f_exponentials\n",
    "                    if j <= len(f_coefficient_range):\n",
    "                        f_AO_set = np.append(f_AO_set, np.array([f_AO_contributions, i + 1])) \n",
    "                        f_ref_set = np.append(f_ref_set, f_AO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            i += 1\n",
    "        Ci = sympy.symbols(\"Ci\", real = True)\n",
    "        one_electron_wavefunctions = np.append(one_electron_wavefunctions, s_AO_set)\n",
    "        one_electron_wavefunctions = np.append(one_electron_wavefunctions, p_AO_set)\n",
    "        one_electron_wavefunctions = np.append(one_electron_wavefunctions, d_AO_set)\n",
    "        one_electron_wavefunctions = np.append(one_electron_wavefunctions, f_AO_set)\n",
    "        exp_set = np.append(exp_set, s_exp_set)\n",
    "        exp_set = np.append(exp_set, p_exp_set)\n",
    "        exp_set = np.append(exp_set, d_exp_set)\n",
    "        exp_set = np.append(exp_set, f_exp_set)\n",
    "        one_electron_AO_eqns = np.array([])\n",
    "        k = 0\n",
    "        for k in range(0, len(s_ref_set) * s_exponentials):\n",
    "            current_s_AO_eqn = Ci * exp_set[k]\n",
    "            one_electron_AO_eqns = np.append(one_electron_AO_eqns, current_s_AO_eqn)\n",
    "            k += 1\n",
    "        p_gaussian_start_index = (len(s_ref_set) * s_exponentials) - 1\n",
    "        p_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        p_gaussian_count = p_gaussian_end_index - p_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(p_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials + 1])\n",
    "            current_basis_coefficients = coefficient_sequence[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials]\n",
    "            current_exponentials = exp_set[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials* k + p_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_AO_eqns = np.append(one_electron_AO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        d_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        d_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        d_gaussian_count = d_gaussian_end_index - d_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(d_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials + 1])\n",
    "            current_basis_coefficients = coefficient_sequence[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials]\n",
    "            current_exponentials = exp_set[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials* k + d_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_AO_eqns = np.append(one_electron_AO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        f_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        f_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials + len(f_ref_set) * f_exponentials) - 1\n",
    "        f_gaussian_count = f_gaussian_end_index - f_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(f_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials + 1])\n",
    "            current_basis_coefficients = coefficient_sequence[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials]\n",
    "            current_exponentials = exp_set[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials* k + f_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_AO_eqns = np.append(one_electron_AO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "                    \n",
    "        return one_electron_wavefunctions, one_electron_AO_eqns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87a0700d-8204-476e-8c1f-786a812fbafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.097]\n",
      "[5.50e-02 4.98e+02]\n",
      "[5.50e-02 4.98e+02]\n",
      "[]\n",
      "[0.068]\n",
      "[-0.19  1.18]\n",
      "[-0.19  1.18]\n",
      "[]\n",
      "[590.]\n",
      "[0.00024 0.0543 ]\n",
      "[0.00024 0.0543 ]\n",
      "[]\n",
      "[0.0071]\n",
      "[4.1e+00 4.4e-04]\n",
      "[4.1e+00 4.4e-04]\n",
      "[]\n",
      "[-0.0048]\n",
      "[ 0.022 -0.095]\n",
      "[ 0.022 -0.095]\n",
      "[]\n",
      "[-0.00011]\n",
      "[0.0091 0.228 ]\n",
      "[0.0091 0.228 ]\n",
      "[]\n",
      "[45.]\n",
      "[-0.088    0.00512]\n",
      "[-0.088    0.00512]\n",
      "[]\n",
      "(array([0.097*exp(-4.62*r), 1, 0.068*exp(-10.98*r), 2, 590.0*exp(-3.88*r),\n",
      "       3, 0.0071*exp(-2.85*r), 4, -0.0048*exp(-2.56*r), 5,\n",
      "       -0.00011*exp(-3.19*r), 6, 45.0*exp(-4.73*r), 7,\n",
      "       0.055*exp(-2.91*r) + 498.0*exp(-0.244*r), 1,\n",
      "       1.18*exp(-3.15*r) - 0.19*exp(-2.8*r), 2,\n",
      "       0.00024*exp(-2.98*r) + 0.0543*exp(-0.88*r), 3,\n",
      "       4.1*exp(-3.25*r) + 0.00044*exp(-0.7*r), 4,\n",
      "       0.022*exp(-9.58*r) - 0.095*exp(-2.98*r), 5,\n",
      "       0.0091*exp(-7.43*r) + 0.228*exp(-0.97*r), 6,\n",
      "       -0.088*exp(-2.9*r) + 0.00512*exp(-0.66*r), 7], dtype=object), array([Ci*exp(-4.62*r), Ci*exp(-10.98*r), Ci*exp(-3.88*r),\n",
      "       Ci*exp(-2.85*r), Ci*exp(-2.56*r), Ci*exp(-3.19*r), Ci*exp(-4.73*r),\n",
      "       Ci*exp(-2.91*r) + 590.0*exp(-3.88*r),\n",
      "       Ci*exp(-0.244*r) + 0.0071*exp(-2.85*r),\n",
      "       Ci*exp(-2.8*r) + 0.0543*exp(-0.88*r),\n",
      "       Ci*exp(-2.98*r) + 4.1*exp(-3.25*r),\n",
      "       Ci*exp(-3.25*r) - 0.0048*exp(-2.56*r),\n",
      "       Ci*exp(-0.88*r) + 0.022*exp(-9.58*r),\n",
      "       Ci*exp(-0.7*r) - 0.00011*exp(-3.19*r),\n",
      "       Ci*exp(-7.43*r) + 0.0091*exp(-7.43*r),\n",
      "       Ci*exp(-0.97*r) - 0.088*exp(-2.9*r)], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "molecular_graph_details = molecular_graph(orbital_overlaps = np.array([\"1_2\", \"2_1\", \"1_6\", \"6_1\", \"1_7\", \"7_1\", \"2_3\", \"3_2\", \"3_4\", \"4_3\", \"3_7\", \"7_3\", \"4_5\", \"5_4\", \"5_6\", \"6_5\", \"5_7\", \"7_5\"]), n_atoms = 7, maximum_s_el = 1, maximum_p_el = 2, maximum_d_el = 0, maximum_f_el = 0)\n",
    "initial_state_tensor = build_graph_tensor(csv_filepath, record_filepath, record_filename)[0]\n",
    "variable_state_tensor = build_graph_tensor(csv_filepath, record_filepath, record_filename)[1]\n",
    "bonding_states = {\"s\":0, \"p\":(1,2), \"d\":(3,7), \"f\":(8,)}\n",
    "variable_state_tensor = variable_state_tensor.astype(\"float\")\n",
    "initial_state_floats = initial_state_tensor[1:].astype(\"float\")\n",
    "initial_state_labels = initial_state_tensor[0].astype(\"str\")\n",
    "basis_coefficient_range = (list(initial_state_labels).index(\"d1\"), list(initial_state_labels).index(\"exp1\"))\n",
    "exponential_range = (list(initial_state_labels).index(\"exp1\"), len(initial_state_labels) - 1)\n",
    "\n",
    "EH_solver = EH_molecular_orbitals(input_tensor = initial_state_floats, atomic_orbital_states = bonding_states, n_atoms = 7, exponential_range = exponential_range, maximum_s_el = molecular_graph_details.maximum_s_el, maximum_p_el = molecular_graph_details.maximum_p_el, maximum_d_el = molecular_graph_details.maximum_d_el, maximum_f_el = molecular_graph_details.maximum_f_el)\n",
    "print(EH_solver.construct_basis_AOs(input_tensor = EH_solver.input_tensor, atomic_orbital_states = EH_solver.atomic_orbital_states, n_atoms = EH_solver.n_atoms, exponential_range = EH_solver.exponential_range, maximum_s_el = EH_solver.maximum_s_el, maximum_p_el = EH_solver.maximum_p_el, maximum_d_el = EH_solver.maximum_d_el, maximum_f_el = EH_solver.maximum_f_el))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac83e76-93c2-4572-90a8-23b6806d47e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.40e+00  5.00e+00  8.00e+00  7.10e-03  4.10e+00  4.40e-04  2.85e+00\n",
      "   3.25e+00  7.00e-01]\n",
      " [ 1.90e+00  3.00e+00  5.70e+01 -4.80e-03  2.20e-02 -9.50e-02  2.56e+00\n",
      "   9.58e+00  2.98e+00]\n",
      " [ 2.70e+00  3.38e+00  5.70e+01 -1.10e-04  9.10e-03  2.28e-01  3.19e+00\n",
      "   7.43e+00  9.70e-01]]\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "print(initial_state_floats[basis_coefficient_range[0]:basis_coefficient_range[1]])\n",
    "print(basis_coefficient_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98327f45-ea23-4957-ac5b-a38cf08f766c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maximum_s_el' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmaximum_s_el\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maximum_s_el' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f059dd0a-ddb7-4376-ae35-4268c972d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Matrix([\n",
      "[1, 0, 0, 0],\n",
      "[0, 1, 0, 0],\n",
      "[0, 0, 1, 0],\n",
      "[0, 0, 0, 1]]), (0, 1, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "mat = sympy.Matrix([[1,5,3,-3], [0,1,-1,8], [0,0,0,3], [0,0,1,1]])\n",
    "print(mat.rref())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08613606-790b-4566-b6e0-1151217bd32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function rref in module sympy.matrices.matrices:\n",
      "\n",
      "rref(self, iszerofunc=<function _iszero at 0x28ed23010>, simplify=False, pivots=True, normalize_last=True)\n",
      "    Return reduced row-echelon form of matrix and indices of pivot vars.\n",
      "    \n",
      "    Parameters\n",
      "    ==========\n",
      "    \n",
      "    iszerofunc : Function\n",
      "        A function used for detecting whether an element can\n",
      "        act as a pivot.  ``lambda x: x.is_zero`` is used by default.\n",
      "    \n",
      "    simplify : Function\n",
      "        A function used to simplify elements when looking for a pivot.\n",
      "        By default SymPy's ``simplify`` is used.\n",
      "    \n",
      "    pivots : True or False\n",
      "        If ``True``, a tuple containing the row-reduced matrix and a tuple\n",
      "        of pivot columns is returned.  If ``False`` just the row-reduced\n",
      "        matrix is returned.\n",
      "    \n",
      "    normalize_last : True or False\n",
      "        If ``True``, no pivots are normalized to `1` until after all\n",
      "        entries above and below each pivot are zeroed.  This means the row\n",
      "        reduction algorithm is fraction free until the very last step.\n",
      "        If ``False``, the naive row reduction procedure is used where\n",
      "        each pivot is normalized to be `1` before row operations are\n",
      "        used to zero above and below the pivot.\n",
      "    \n",
      "    Examples\n",
      "    ========\n",
      "    \n",
      "    >>> from sympy import Matrix\n",
      "    >>> from sympy.abc import x\n",
      "    >>> m = Matrix([[1, 2], [x, 1 - 1/x]])\n",
      "    >>> m.rref()\n",
      "    (Matrix([\n",
      "    [1, 0],\n",
      "    [0, 1]]), (0, 1))\n",
      "    >>> rref_matrix, rref_pivots = m.rref()\n",
      "    >>> rref_matrix\n",
      "    Matrix([\n",
      "    [1, 0],\n",
      "    [0, 1]])\n",
      "    >>> rref_pivots\n",
      "    (0, 1)\n",
      "    \n",
      "    ``iszerofunc`` can correct rounding errors in matrices with float\n",
      "    values. In the following example, calling ``rref()`` leads to\n",
      "    floating point errors, incorrectly row reducing the matrix.\n",
      "    ``iszerofunc= lambda x: abs(x)<1e-9`` sets sufficiently small numbers\n",
      "    to zero, avoiding this error.\n",
      "    \n",
      "    >>> m = Matrix([[0.9, -0.1, -0.2, 0], [-0.8, 0.9, -0.4, 0], [-0.1, -0.8, 0.6, 0]])\n",
      "    >>> m.rref()\n",
      "    (Matrix([\n",
      "    [1, 0, 0, 0],\n",
      "    [0, 1, 0, 0],\n",
      "    [0, 0, 1, 0]]), (0, 1, 2))\n",
      "    >>> m.rref(iszerofunc=lambda x:abs(x)<1e-9)\n",
      "    (Matrix([\n",
      "    [1, 0, -0.301369863013699, 0],\n",
      "    [0, 1, -0.712328767123288, 0],\n",
      "    [0, 0,         0,          0]]), (0, 1))\n",
      "    \n",
      "    Notes\n",
      "    =====\n",
      "    \n",
      "    The default value of ``normalize_last=True`` can provide significant\n",
      "    speedup to row reduction, especially on matrices with symbols.  However,\n",
      "    if you depend on the form row reduction algorithm leaves entries\n",
      "    of the matrix, set ``noramlize_last=False``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sympy.Matrix.rref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188560b3-9ff2-4940-a064-50a28f6d3dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
